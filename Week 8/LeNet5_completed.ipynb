{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDbJWoO1yO8e"
      },
      "source": [
        "# Image Classification with CNN - LeNet5 architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JzQxqD6HyO8i"
      },
      "source": [
        "In this exercise, we will apply the LeNet5 algorithm to the Fashion MNIST dataset and improve your performances."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFyVotRvyO8j"
      },
      "source": [
        "We will first download the data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RTHLyL1fyO8j",
        "outputId": "0d576277-2dbb-4543-d017-a5bb32605db4",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "\u001b[1m29515/29515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "\u001b[1m26421880/26421880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "\u001b[1m5148/5148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "\u001b[1m4422102/4422102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "# TODO: Load the dataset\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "# # # If your computer is slow, try to use a subset of data, e.g.\n",
        "# X_train = X_train[:10000]\n",
        "# y_train = y_train[:10000]\n",
        "# X_test = X_test[:2000]\n",
        "# y_test = y_test[:2000]\n",
        "X_train.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8ShXIANyO8l"
      },
      "source": [
        "As you already know, this dataset contains 10 classes:\n",
        "* 0:\tT-shirt/top\n",
        "* 1:\tTrouser\n",
        "* 2:\tPullover\n",
        "* 3:\tDress\n",
        "* 4:\tCoat\n",
        "* 5:\tSandal\n",
        "* 6:\tShirt\n",
        "* 7:\tSneaker\n",
        "* 8:\tBag\n",
        "* 9:\tAnkle boot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BvNG0PbyO8l"
      },
      "source": [
        "You can have a look at some images if needed, even if you already know them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "lnjqgv-GyO8m",
        "outputId": "d6e4b6f2-024a-40d3-fef4-a812f8f3798a",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGzCAYAAABpdMNsAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAIxpJREFUeJzt3XtwVPX9//HXhpDllmwIkJsECBdBReiUCmVQRMkQYAZFmfHaERxHqwYLUtTSqoB1mq84RQdLYaZjoU4FKR2BYpVWQcJoAxUUGUabITRyEQKFkt2QQAjk/P7gx9YVkJwPu3kn4fmY2Rmye9573vnkJC9Ozua9Ac/zPAEA0MSSrBsAAFyZCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIOAyzJkzR4FAQEeOHLFuBWhxCCAAgAkCCABgggACAJgggIA4OHLkiO666y6lpaWpS5cumjZtmk6ePBl9fMmSJbr11luVmZmpYDCoa6+9VosWLTrveRoaGjRnzhzl5uaqQ4cOuuWWW/TFF1+oV69emjJlShN+RkDiJVs3ALQGd911l3r16qXi4mJt3rxZCxYs0LFjx/TGG29IkhYtWqTrrrtOt912m5KTk7V27Vo9/vjjamhoUFFRUfR5Zs2apXnz5mnChAkqLCzU559/rsLCwpgwA1oND4Cz2bNne5K82267Leb+xx9/3JPkff75557neV5tbe15tYWFhV7v3r2jH1dWVnrJycnexIkTY7abM2eOJ8mbPHly/D8BwBC/ggPi4JtnMZL0xBNPSJLeffddSVL79u2jj4XDYR05ckQ333yz/v3vfyscDkuS1q9fr9OnT+vxxx+/4HMBrQ2/ggPioF+/fjEf9+nTR0lJSfrqq68kSR9//LFmz56t0tJS1dbWxmwbDocVCoW0Z88eSVLfvn1jHs/IyFDnzp0T1zxghAACEiAQCET/vXv3bo0ePVoDBgzQ/PnzlZeXp5SUFL377rt65ZVX1NDQYNgpYIcAAuJg165dys/Pj35cXl6uhoYG9erVS2vXrlVdXZ3+8pe/qEePHtFtPvzww5jn6NmzZ7T2m8919OhRHTt2LMGfAdD0uAYExMHChQtjPn7ttdckSePGjVObNm0kSZ7nRR8Ph8NasmRJTM3o0aOVnJx83suzf/Ob3ySiZcAcZ0BAHFRUVOi2227T2LFjVVpaqj/+8Y+67777NHjwYLVr104pKSmaMGGCfvzjH+v48eP63e9+p8zMTB08eDD6HFlZWZo2bZp+/etfR5/r888/13vvvaeuXbvG/FoPaA04AwLiYMWKFQoGg/rZz36mv/71r5o6dapef/11SVL//v315z//WYFAQDNnztTixYv1yCOPaNq0aec9z0svvaTnnntOn3zyiWbOnKny8nL9/e9/l+d5ateuXVN/WkBCBbxv/l4AQLNTVVWlzp0768UXX9QvfvEL63aAuOEMCGhGTpw4cd59r776qiRp1KhRTdsMkGBcAwKakRUrVmjp0qUaP368OnXqpI8++kjLly/XmDFjNGLECOv2gLgigIBmZNCgQUpOTta8efMUiUSiL0x48cUXrVsD4o5rQAAAE1wDAgCYIIAAACaa3TWghoYGHThwQKmpqfzhHQC0QJ7nqbq6Wrm5uUpKuvh5TrMLoAMHDigvL8+6DQDAZdq3b5+6d+9+0cebXQClpqZKOtt4WlqacTcAAL8ikYjy8vKiP88vJmEBtHDhQr388suqrKzU4MGD9dprr2no0KGXrDv3a7e0tDQCCABasEtdRknIixBWrFihGTNmaPbs2fr00081ePBgFRYW6vDhw4nYHQCgBUpIAM2fP18PP/ywHnzwQV177bVavHixOnTooN///veJ2B0AoAWKewCdOnVK27ZtU0FBwf92kpSkgoIClZaWnrd9XV2dIpFIzA0A0PrFPYCOHDmiM2fOKCsrK+b+rKwsVVZWnrd9cXGxQqFQ9MYr4ADgymD+h6izZs1SOByO3vbt22fdEgCgCcT9VXBdu3ZVmzZtdOjQoZj7Dx06pOzs7PO2DwaDCgaD8W4DANDMxf0MKCUlRUOGDNH69euj9zU0NGj9+vUaPnx4vHcHAGihEvJ3QDNmzNDkyZP1gx/8QEOHDtWrr76qmpoaPfjgg4nYHQCgBUpIAN199936z3/+o+eff16VlZX63ve+p3Xr1p33wgQAwJWr2b0fUCQSUSgUUjgcZhICALRAjf05bv4qOADAlYkAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACAiWTrBmCvtrbWqe7LL7/0XRMOh5325VddXZ1TXX19ve+apCT//49r06ZNk9Q0NDT4rpGk5GT/PxqysrJ813Ts2NF3TYcOHZqkRpI6derku8bleLhSsVIAABMEEADARNwDaM6cOQoEAjG3AQMGxHs3AIAWLiHXgK677jp98MEH/9uJw++TAQCtW0KSITk5WdnZ2Yl4agBAK5GQa0C7du1Sbm6uevfurfvvv1979+696LZ1dXWKRCIxNwBA6xf3ABo2bJiWLl2qdevWadGiRaqoqNBNN92k6urqC25fXFysUCgUveXl5cW7JQBAMxTwPM9L5A6qqqrUs2dPzZ8/Xw899NB5j9fV1cX8zUYkElFeXp7C4bDS0tIS2Rr+P/4O6H/4O6Cz+Dugs/g7IDeRSEShUOiSP8cT/uqA9PR0XX311SovL7/g48FgUMFgMNFtAACamYRH9fHjx7V7927l5OQkelcAgBYk7gE0c+ZMlZSU6KuvvtI//vEP3XHHHWrTpo3uvffeeO8KANCCxf1XcPv379e9996ro0ePqlu3brrxxhu1efNmdevWLd67AgC0YHEPoLfeeiveT9kquFywv+aaa3zXTJw40XfNnj17fNdIbheqT58+7bvmu17GfzGuf/zc2i4gBwIBp7oEvzYpqqmu/6akpDjVdenSxXdN27Ztfde4vIBj3rx5vmskKT8/36kuEVrXdxsAoMUggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgIuFvSNdUXN7J0mVooCStXLnSd82vfvUr3zXp6em+ayKRiO8a1/dqcnmHThe9e/f2XePam8swUpd3X3UZlupyjDfVUFHJ7d1XXfpz2c+ZM2d810hua+7ytd2/f7/vmgceeMB3jeT2cy83N9fX9o1dN86AAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmmu007DNnzviaYOs62drFmjVrfNe0b9/ed43LlOVevXr5rjlx4oTvGknq1KmT7xqXz8llYrLLFGNXp0+f9l3jMjE5EAj4rnHlMj06JSXFd43L2rl8r7v+fHD5OrmsQ01Nje8aV1u2bPFd06dPH1/bN3YaPWdAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATLSaYaSNHX73TevWrfNdI0mlpaW+a7p16+a7JiMjw3eNy9BTl2GfklRdXe27xmW4o2t/LhoaGnzXtGvXzndN586dfde4DLl0OR4kt2GkJ0+ebJIalwGmrk6dOuW7xuX74tixY75rsrKyfNdIUocOHXzX5OXl+dq+sV9XzoAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYaLbDSFNSUpyGL/oxffp0p7r+/fv7rnEZupienu67pl+/fr5rtmzZ4rtGchvc2VQCgYBTXVKS//+T1dTU+K5xGajpst7BYNB3jeQ2+DTR36/nuAynra+vd9qXy3HkMhg5FAr5rnEZlCpJe/bs8V3Ttm1bX9s3dpgtZ0AAABMEEADAhO8A2rRpkyZMmKDc3FwFAgGtXr065nHP8/T8888rJydH7du3V0FBgXbt2hWvfgEArYTvAKqpqdHgwYO1cOHCCz4+b948LViwQIsXL9aWLVvUsWNHFRYWOl0DAQC0Xr5fhDBu3DiNGzfugo95nqdXX31Vzz77rG6//XZJ0htvvKGsrCytXr1a99xzz+V1CwBoNeJ6DaiiokKVlZUqKCiI3hcKhTRs2LCLvo11XV2dIpFIzA0A0PrFNYAqKyslnf9e5VlZWdHHvq24uFihUCh68/ve4wCAlsn8VXCzZs1SOByO3vbt22fdEgCgCcQ1gLKzsyVJhw4dirn/0KFD0ce+LRgMKi0tLeYGAGj94hpA+fn5ys7O1vr166P3RSIRbdmyRcOHD4/nrgAALZzvV8EdP35c5eXl0Y8rKiq0fft2ZWRkqEePHpo+fbpefPFF9evXT/n5+XruueeUm5uriRMnxrNvAEAL5zuAtm7dqltuuSX68YwZMyRJkydP1tKlS/X000+rpqZGjzzyiKqqqnTjjTdq3bp1ateuXfy6BgC0eL4DaNSoUd85DDAQCOiFF17QCy+8cFmN+bV161bfNWVlZU77uuuuu3zXfPDBB75rkpP9z4rNyMjwXdOlSxffNZJUVVXlVOeXyzr4HZ54jsugy6YaEuqyDq4DY12GsroM4Wzs0Mpvch0068Llc3K5jn3ixAnfNd/8TZQfLkMB/A4+bez25q+CAwBcmQggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJvyP122mXCa8XuxdWi/FZdL3m2++6bvGZaru119/7bumvr7ed40k1dTU+K5xeVsOl8nMLlOWXetSUlJ816SmpvqucZmG7fI1cnX69GnfNS6TrV0mibvUSG7HQ11dne+a//73v75rXCZoS1J6errvGr/9NXYNOAMCAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgotUMI33qqad810yaNCkBnVyYy/DJhoYG3zUuQ1ldBkJKzXuwqOvn5Hme7xqX/ly+Ti7DSJuSy9q5HEMu3xeuA3crKyt917gMCXU5HppS3759fW3f2DXgDAgAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAICJ5j3d0IevvvrKd01paWn8G7kIl+GYKSkpvmvS0tJ814TDYd81knT8+HGnOr9chn26DMZ03VdTDY0NBoO+a1x6c92XC5d1qKmp8V1TW1vru0aSTp8+7bvG5Xu9KQfNuhzjfoeRNna9OQMCAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgotkOI123bp06dOjQ6O2HDh2awG4uX1KS/6x3GVDYqVMn3zWu2rZt67vGZUio62BRFy6DJNu0adMk+6mrq/NdU19f77tGchti2r59e981LsM+XQalug77dKlzGe578OBB3zUuaye5Ha+5ubm+tm/soGLOgAAAJgggAIAJ3wG0adMmTZgwQbm5uQoEAlq9enXM41OmTFEgEIi5jR07Nl79AgBaCd8BVFNTo8GDB2vhwoUX3Wbs2LE6ePBg9LZ8+fLLahIA0Pr4vsI2btw4jRs37ju3CQaDys7Odm4KAND6JeQa0MaNG5WZman+/fvrscce09GjRy+6bV1dnSKRSMwNAND6xT2Axo4dqzfeeEPr16/XSy+9pJKSEo0bN+6i70NeXFysUCgUveXl5cW7JQBAMxT3vwO65557ov++/vrrNWjQIPXp00cbN27U6NGjz9t+1qxZmjFjRvTjSCRCCAHAFSDhL8Pu3bu3unbtqvLy8gs+HgwGlZaWFnMDALR+CQ+g/fv36+jRo8rJyUn0rgAALYjvX8EdP3485mymoqJC27dvV0ZGhjIyMjR37lxNmjRJ2dnZ2r17t55++mn17dtXhYWFcW0cANCy+Q6grVu36pZbbol+fO76zeTJk7Vo0SLt2LFDf/jDH1RVVaXc3FyNGTNGv/zlL53mNwEAWi/fATRq1KjvHA75t7/97bIaOmfHjh1q165do7cfP358XPabKC4DAF2GcNbW1vquOXnypO8ayW3QpctQVhcXe9XlpbgMCXUZWOmydi7Hg8vnI7kdEy5/QtFU3xeuQ1ldBqw2dhDnN506dcp3jauUlBTfNX7XobHff8yCAwCYIIAAACYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYiPtbcsfL119/7Wtq6zffCrw56tSpk+8al0nGp0+f9l3jMs1Zcptk3Jz348plzV24rIPrNGyXurZt2/qucZ1S7ZfLVGvJbUp1Q0OD7xo/k//Pqaur813juq/U1FSnfV0KZ0AAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMNNthpEePHvU13PCqq65KYDeXz2W4o+d5vmvOnDnju8Z1IKTLgEeXAYou6+AyEFJy+zolJTXN/+NcenMdRuryOQWDwSapaaohvZJUXV3tu8ZlaKzLINdjx475rpHcBovm5OT42r5jx46N2o4zIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYIIAAACaa7TDS1NRUpaSkNHr7yspK3/vIz8/3XePqgQce8F2zdOlS3zUuwxNdh5G6DFB04TJY1GUoqyuX4ZMuAzVd1sFlkKsknTp1yqmuKbh8TsePH3fal8sQU5fvixMnTviucR0063Ic+a1p7PacAQEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADDRbIeRjh8/Xh06dGj09nPnzvW9jwULFviukdwGNX7yySe+a2pqanzXuAzhDIVCvmsk6eTJk75rXAZ3ukhKarr/W7kMx3SpacphpC77chEOh33XNMUwzXNcvp9cfj64DDA9cuSI7xpJSk72/2Pf7/dTY7fnDAgAYIIAAgCY8BVAxcXFuuGGG5SamqrMzExNnDhRZWVlMducPHlSRUVF6tKlizp16qRJkybp0KFDcW0aANDy+QqgkpISFRUVafPmzXr//fdVX1+vMWPGxFyrePLJJ7V27VqtXLlSJSUlOnDggO688864Nw4AaNl8XY1at25dzMdLly5VZmamtm3bppEjRyocDuv111/XsmXLdOutt0qSlixZomuuuUabN2/WD3/4w/h1DgBo0S7rGtC5V7BkZGRIkrZt26b6+noVFBREtxkwYIB69Oih0tLSCz5HXV2dIpFIzA0A0Po5B1BDQ4OmT5+uESNGaODAgZKkyspKpaSkKD09PWbbrKwsVVZWXvB5iouLFQqFore8vDzXlgAALYhzABUVFWnnzp166623LquBWbNmKRwOR2/79u27rOcDALQMTn+IOnXqVL3zzjvatGmTunfvHr0/Oztbp06dUlVVVcxZ0KFDh5SdnX3B5woGgwoGgy5tAABaMF9nQJ7naerUqVq1apU2bNig/Pz8mMeHDBmitm3bav369dH7ysrKtHfvXg0fPjw+HQMAWgVfZ0BFRUVatmyZ1qxZo9TU1Oh1nVAopPbt2ysUCumhhx7SjBkzlJGRobS0ND3xxBMaPnw4r4ADAMTwFUCLFi2SJI0aNSrm/iVLlmjKlCmSpFdeeUVJSUmaNGmS6urqVFhYqN/+9rdxaRYA0HoEPNdphQkSiUQUCoUUDoeVlpbW6LotW7b43te8efN810jSiRMnfNdUVVX5rjn3t1R+fPHFF01SI0mBQMB3jcugRpdBkqdPn/Zd41rnsg4uQ1ldenNdB5dhrikpKb5rXIZ9NtVAW8ltSKjLcF+Xwb4uP1Oksy/88usnP/mJr+0b+3OcWXAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABPNdhr2sWPHfE3Ddpnei7Ncp+q61B0/ftx3jcvX1mXKsnT2TRebK5ep4C6T2yUpHA77rqmpqfFdU19f32z3I7lNqXY5xr/5DtKNNX78eN81ktS7d2+nOj+Yhg0AaNYIIACACQIIAGCCAAIAmCCAAAAmCCAAgAkCCABgggACAJgggAAAJgggAIAJAggAYIIAAgCYSLZu4GKSkpIYMNpEXAYhXk4dAEicAQEAjBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAw4SuAiouLdcMNNyg1NVWZmZmaOHGiysrKYrYZNWqUAoFAzO3RRx+Na9MAgJbPVwCVlJSoqKhImzdv1vvvv6/6+nqNGTNGNTU1Mds9/PDDOnjwYPQ2b968uDYNAGj5kv1svG7dupiPly5dqszMTG3btk0jR46M3t+hQwdlZ2fHp0MAQKt0WdeAwuGwJCkjIyPm/jfffFNdu3bVwIEDNWvWLNXW1l70Oerq6hSJRGJuAIDWz9cZ0Dc1NDRo+vTpGjFihAYOHBi9/7777lPPnj2Vm5urHTt26JlnnlFZWZnefvvtCz5PcXGx5s6d69oGAKCFCnie57kUPvbYY3rvvff00UcfqXv37hfdbsOGDRo9erTKy8vVp0+f8x6vq6tTXV1d9ONIJKK8vDyFw2GlpaW5tAYAMBSJRBQKhS75c9zpDGjq1Kl65513tGnTpu8MH0kaNmyYJF00gILBoILBoEsbAIAWzFcAeZ6nJ554QqtWrdLGjRuVn59/yZrt27dLknJycpwaBAC0Tr4CqKioSMuWLdOaNWuUmpqqyspKSVIoFFL79u21e/duLVu2TOPHj1eXLl20Y8cOPfnkkxo5cqQGDRqUkE8AANAy+boGFAgELnj/kiVLNGXKFO3bt08/+tGPtHPnTtXU1CgvL0933HGHnn322UZfz2ns7w4BAM1TQq4BXSqr8vLyVFJS4ucpAQBXKGbBAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADABAEEADBBAAEATBBAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMJFs38G2e50mSIpGIcScAABfnfn6f+3l+Mc0ugKqrqyVJeXl5xp0AAC5HdXW1QqHQRR8PeJeKqCbW0NCgAwcOKDU1VYFAIOaxSCSivLw87du3T2lpaUYd2mMdzmIdzmIdzmIdzmoO6+B5nqqrq5Wbm6ukpItf6Wl2Z0BJSUnq3r37d26TlpZ2RR9g57AOZ7EOZ7EOZ7EOZ1mvw3ed+ZzDixAAACYIIACAiRYVQMFgULNnz1YwGLRuxRTrcBbrcBbrcBbrcFZLWodm9yIEAMCVoUWdAQEAWg8CCABgggACAJgggAAAJgggAICJFhNACxcuVK9evdSuXTsNGzZM//znP61banJz5sxRIBCIuQ0YMMC6rYTbtGmTJkyYoNzcXAUCAa1evTrmcc/z9PzzzysnJ0ft27dXQUGBdu3aZdNsAl1qHaZMmXLe8TF27FibZhOkuLhYN9xwg1JTU5WZmamJEyeqrKwsZpuTJ0+qqKhIXbp0UadOnTRp0iQdOnTIqOPEaMw6jBo16rzj4dFHHzXq+MJaRACtWLFCM2bM0OzZs/Xpp59q8ODBKiws1OHDh61ba3LXXXedDh48GL199NFH1i0lXE1NjQYPHqyFCxde8PF58+ZpwYIFWrx4sbZs2aKOHTuqsLBQJ0+ebOJOE+tS6yBJY8eOjTk+li9f3oQdJl5JSYmKioq0efNmvf/++6qvr9eYMWNUU1MT3ebJJ5/U2rVrtXLlSpWUlOjAgQO68847DbuOv8asgyQ9/PDDMcfDvHnzjDq+CK8FGDp0qFdUVBT9+MyZM15ubq5XXFxs2FXTmz17tjd48GDrNkxJ8latWhX9uKGhwcvOzvZefvnl6H1VVVVeMBj0li9fbtBh0/j2Onie502ePNm7/fbbTfqxcvjwYU+SV1JS4nne2a9927ZtvZUrV0a3+fLLLz1JXmlpqVWbCfftdfA8z7v55pu9adOm2TXVCM3+DOjUqVPatm2bCgoKovclJSWpoKBApaWlhp3Z2LVrl3Jzc9W7d2/df//92rt3r3VLpioqKlRZWRlzfIRCIQ0bNuyKPD42btyozMxM9e/fX4899piOHj1q3VJChcNhSVJGRoYkadu2baqvr485HgYMGKAePXq06uPh2+twzptvvqmuXbtq4MCBmjVrlmpray3au6hmNw37244cOaIzZ84oKysr5v6srCz961//MurKxrBhw7R06VL1799fBw8e1Ny5c3XTTTdp586dSk1NtW7PRGVlpSRd8Pg499iVYuzYsbrzzjuVn5+v3bt36+c//7nGjRun0tJStWnTxrq9uGtoaND06dM1YsQIDRw4UNLZ4yElJUXp6ekx27bm4+FC6yBJ9913n3r27Knc3Fzt2LFDzzzzjMrKyvT2228bdhur2QcQ/mfcuHHRfw8aNEjDhg1Tz5499ac//UkPPfSQYWdoDu65557ov6+//noNGjRIffr00caNGzV69GjDzhKjqKhIO3fuvCKug36Xi63DI488Ev339ddfr5ycHI0ePVq7d+9Wnz59mrrNC2r2v4Lr2rWr2rRpc96rWA4dOqTs7GyjrpqH9PR0XX311SovL7duxcy5Y4Dj43y9e/dW165dW+XxMXXqVL3zzjv68MMPY94/LDs7W6dOnVJVVVXM9q31eLjYOlzIsGHDJKlZHQ/NPoBSUlI0ZMgQrV+/PnpfQ0OD1q9fr+HDhxt2Zu/48ePavXu3cnJyrFsxk5+fr+zs7JjjIxKJaMuWLVf88bF//34dPXq0VR0fnudp6tSpWrVqlTZs2KD8/PyYx4cMGaK2bdvGHA9lZWXau3dvqzoeLrUOF7J9+3ZJal7Hg/WrIBrjrbfe8oLBoLd06VLviy++8B555BEvPT3dq6ystG6tSf30pz/1Nm7c6FVUVHgff/yxV1BQ4HXt2tU7fPiwdWsJVV1d7X322WfeZ5995kny5s+f73322Wfenj17PM/zvP/7v//z0tPTvTVr1ng7duzwbr/9di8/P987ceKEcefx9V3rUF1d7c2cOdMrLS31KioqvA8++MD7/ve/7/Xr1887efKkdetx89hjj3mhUMjbuHGjd/DgweittrY2us2jjz7q9ejRw9uwYYO3detWb/jw4d7w4cMNu46/S61DeXm598ILL3hbt271KioqvDVr1ni9e/f2Ro4cadx5rBYRQJ7nea+99prXo0cPLyUlxRs6dKi3efNm65aa3N133+3l5OR4KSkp3lVXXeXdfffdXnl5uXVbCffhhx96ks67TZ482fO8sy/Ffu6557ysrCwvGAx6o0eP9srKymybToDvWofa2lpvzJgxXrdu3by2bdt6PXv29B5++OFW95+0C33+krwlS5ZEtzlx4oT3+OOPe507d/Y6dOjg3XHHHd7Bgwftmk6AS63D3r17vZEjR3oZGRleMBj0+vbt6z311FNeOBy2bfxbeD8gAICJZn8NCADQOhFAAAATBBAAwAQBBAAwQQABAEwQQAAAEwQQAMAEAQQAMEEAAQBMEEAAABMEEADAxP8D8dsXfWFSv2cAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# TODO: Explore the data, display some input images\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "label_class = ['top', 'trouser', 'pullover', 'dress', 'coat', 'sandal', 'shirt', 'sneaker', 'bag', 'ankle boot']\n",
        "\n",
        "idx = np.random.randint(X_train.shape[0])\n",
        "\n",
        "plt.imshow(X_train[idx], cmap=\"gray_r\")\n",
        "plt.title(label_class[y_train[idx]])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AdYH6XW1yO8n"
      },
      "source": [
        "Make the data preparation and preprocessing: scale and reshape the data, put the labels to the good shape."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "fjv8XMPByO8o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "003f3cbb-033d-4bc7-cd86-31ef806f3035"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# TODO: Make the data preparation\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "y_train_cat = to_categorical(y_train, num_classes=10)\n",
        "y_test_cat = to_categorical(y_test, num_classes=10)\n",
        "\n",
        "X_train_norm = X_train/255\n",
        "X_test_norm = X_test/255\n",
        "\n",
        "\n",
        "X_train_norm = X_train_norm.reshape(X_train_norm.shape[0], 28, 28, 1)\n",
        "X_test_norm = X_test_norm.reshape(X_test_norm.shape[0], 28, 28, 1)\n",
        "\n",
        "X_train_norm.shape #Should be (60000, 28, 28, 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9LKzxR9yO8o"
      },
      "source": [
        "Now build the LeNet5 architecture. You can reuse the one of the course, or try to build it by yourself.\n",
        "\n",
        "The architecture is the following:\n",
        "\n",
        "<p align=\"center\">\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1WteTU2FPIVMkBKmMxGpFm5OjsX-szTbB\">\n",
        "</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "GKyMFlL6yO8o",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "outputId": "05b9d281-f636-4812-9a44-e40cdd09f47a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ C1 (\u001b[38;5;33mConv2D\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m6\u001b[0m)      │            \u001b[38;5;34m60\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ S2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m6\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ C3 (\u001b[38;5;33mConv2D\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │           \u001b[38;5;34m880\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ S4 (\u001b[38;5;33mMaxPooling2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m400\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ C5 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m120\u001b[0m)            │        \u001b[38;5;34m48,120\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ F6 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m84\u001b[0m)             │        \u001b[38;5;34m10,164\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m850\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ C1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)      │            <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ S2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ C3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">880</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ S4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">400</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ C5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">120</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">48,120</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ F6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">84</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,164</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">850</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m60,074\u001b[0m (234.66 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">60,074</span> (234.66 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m60,074\u001b[0m (234.66 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">60,074</span> (234.66 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# TODO: Build your model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import MaxPooling2D, Conv2D, Flatten, Dense\n",
        "\n",
        "\n",
        "def lenet5():\n",
        "\n",
        "    model = Sequential()\n",
        "\n",
        "    # Layer C1\n",
        "    model.add(Conv2D(filters=6, name='C1', kernel_size=(3, 3), activation='relu', input_shape=(28,28,1)))\n",
        "    # Layer S2\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2), name='S2'))\n",
        "    # Layer C3\n",
        "    model.add(Conv2D(filters=16, name='C3', kernel_size=(3, 3), activation='relu'))\n",
        "    # Layer S4\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2), name='S4'))\n",
        "    # Before going into layer C5, we flatten our units\n",
        "    model.add(Flatten())\n",
        "    # Layer C5\n",
        "    model.add(Dense(120, activation='relu', name='C5'))\n",
        "    # Layer F6\n",
        "    model.add(Dense(84, activation='relu', name='F6'))\n",
        "    # Output layer\n",
        "    model.add(Dense(units=10, activation = 'softmax'))\n",
        "\n",
        "    return model\n",
        "\n",
        "lenet5().summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1qBEauqyO8p"
      },
      "source": [
        "Now compile and fit your model on your training data. Since this is a multiclass classification, the loss is not `binary_crossentropy` anymore, but `categorical_crossentropy`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nPL3aKnyyO8p",
        "outputId": "6a4f074b-c1f1-4ce7-8ee0-ab79a8964f65",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 168ms/step - accuracy: 0.3676 - loss: 2.0444 - val_accuracy: 0.6673 - val_loss: 0.9752\n",
            "Epoch 2/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.6878 - loss: 0.8721 - val_accuracy: 0.7295 - val_loss: 0.7344\n",
            "Epoch 3/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7379 - loss: 0.6887 - val_accuracy: 0.7601 - val_loss: 0.6334\n",
            "Epoch 4/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7779 - loss: 0.5932 - val_accuracy: 0.7838 - val_loss: 0.5684\n",
            "Epoch 5/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7981 - loss: 0.5381 - val_accuracy: 0.7906 - val_loss: 0.5529\n",
            "Epoch 6/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8086 - loss: 0.5118 - val_accuracy: 0.8162 - val_loss: 0.5071\n",
            "Epoch 7/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8225 - loss: 0.4854 - val_accuracy: 0.8159 - val_loss: 0.4923\n",
            "Epoch 8/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8297 - loss: 0.4572 - val_accuracy: 0.8131 - val_loss: 0.4973\n",
            "Epoch 9/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8320 - loss: 0.4574 - val_accuracy: 0.8324 - val_loss: 0.4610\n",
            "Epoch 10/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8384 - loss: 0.4430 - val_accuracy: 0.8346 - val_loss: 0.4592\n",
            "Epoch 11/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8411 - loss: 0.4312 - val_accuracy: 0.8364 - val_loss: 0.4492\n",
            "Epoch 12/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8485 - loss: 0.4169 - val_accuracy: 0.8456 - val_loss: 0.4306\n",
            "Epoch 13/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8521 - loss: 0.4095 - val_accuracy: 0.8483 - val_loss: 0.4236\n",
            "Epoch 14/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8573 - loss: 0.4017 - val_accuracy: 0.8470 - val_loss: 0.4225\n",
            "Epoch 15/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8571 - loss: 0.3955 - val_accuracy: 0.8492 - val_loss: 0.4169\n",
            "Epoch 16/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8604 - loss: 0.3825 - val_accuracy: 0.8519 - val_loss: 0.4125\n",
            "Epoch 17/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8635 - loss: 0.3776 - val_accuracy: 0.8546 - val_loss: 0.4058\n",
            "Epoch 18/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8631 - loss: 0.3729 - val_accuracy: 0.8610 - val_loss: 0.3923\n",
            "Epoch 19/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8670 - loss: 0.3707 - val_accuracy: 0.8627 - val_loss: 0.3870\n",
            "Epoch 20/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8690 - loss: 0.3571 - val_accuracy: 0.8556 - val_loss: 0.4012\n",
            "Epoch 21/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8677 - loss: 0.3620 - val_accuracy: 0.8655 - val_loss: 0.3791\n",
            "Epoch 22/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8758 - loss: 0.3445 - val_accuracy: 0.8673 - val_loss: 0.3739\n",
            "Epoch 23/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8754 - loss: 0.3454 - val_accuracy: 0.8651 - val_loss: 0.3755\n",
            "Epoch 24/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8757 - loss: 0.3409 - val_accuracy: 0.8507 - val_loss: 0.3929\n",
            "Epoch 25/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8761 - loss: 0.3411 - val_accuracy: 0.8655 - val_loss: 0.3727\n",
            "Epoch 26/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8785 - loss: 0.3360 - val_accuracy: 0.8734 - val_loss: 0.3600\n",
            "Epoch 27/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8828 - loss: 0.3291 - val_accuracy: 0.8733 - val_loss: 0.3578\n",
            "Epoch 28/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8826 - loss: 0.3259 - val_accuracy: 0.8728 - val_loss: 0.3562\n",
            "Epoch 29/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8808 - loss: 0.3235 - val_accuracy: 0.8764 - val_loss: 0.3501\n",
            "Epoch 30/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8835 - loss: 0.3204 - val_accuracy: 0.8747 - val_loss: 0.3512\n",
            "Epoch 31/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8863 - loss: 0.3134 - val_accuracy: 0.8784 - val_loss: 0.3446\n",
            "Epoch 32/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8873 - loss: 0.3106 - val_accuracy: 0.8735 - val_loss: 0.3492\n",
            "Epoch 33/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8869 - loss: 0.3146 - val_accuracy: 0.8778 - val_loss: 0.3432\n",
            "Epoch 34/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8909 - loss: 0.3017 - val_accuracy: 0.8779 - val_loss: 0.3429\n",
            "Epoch 35/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8881 - loss: 0.3110 - val_accuracy: 0.8738 - val_loss: 0.3531\n",
            "Epoch 36/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8905 - loss: 0.3029 - val_accuracy: 0.8798 - val_loss: 0.3378\n",
            "Epoch 37/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8898 - loss: 0.3019 - val_accuracy: 0.8735 - val_loss: 0.3437\n",
            "Epoch 38/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8902 - loss: 0.3016 - val_accuracy: 0.8810 - val_loss: 0.3349\n",
            "Epoch 39/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8938 - loss: 0.2924 - val_accuracy: 0.8813 - val_loss: 0.3328\n",
            "Epoch 40/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8952 - loss: 0.2901 - val_accuracy: 0.8805 - val_loss: 0.3353\n",
            "Epoch 41/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8941 - loss: 0.2921 - val_accuracy: 0.8778 - val_loss: 0.3386\n",
            "Epoch 42/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8948 - loss: 0.2896 - val_accuracy: 0.8782 - val_loss: 0.3365\n",
            "Epoch 43/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8955 - loss: 0.2866 - val_accuracy: 0.8815 - val_loss: 0.3319\n",
            "Epoch 44/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8976 - loss: 0.2841 - val_accuracy: 0.8782 - val_loss: 0.3333\n",
            "Epoch 45/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8943 - loss: 0.2911 - val_accuracy: 0.8851 - val_loss: 0.3258\n",
            "Epoch 46/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8961 - loss: 0.2809 - val_accuracy: 0.8855 - val_loss: 0.3221\n",
            "Epoch 47/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8969 - loss: 0.2816 - val_accuracy: 0.8822 - val_loss: 0.3279\n",
            "Epoch 48/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8998 - loss: 0.2739 - val_accuracy: 0.8866 - val_loss: 0.3208\n",
            "Epoch 49/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8997 - loss: 0.2768 - val_accuracy: 0.8873 - val_loss: 0.3172\n",
            "Epoch 50/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9021 - loss: 0.2702 - val_accuracy: 0.8872 - val_loss: 0.3189\n",
            "Epoch 51/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9025 - loss: 0.2644 - val_accuracy: 0.8891 - val_loss: 0.3150\n",
            "Epoch 52/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9027 - loss: 0.2645 - val_accuracy: 0.8880 - val_loss: 0.3143\n",
            "Epoch 53/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9036 - loss: 0.2644 - val_accuracy: 0.8890 - val_loss: 0.3106\n",
            "Epoch 54/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9057 - loss: 0.2614 - val_accuracy: 0.8903 - val_loss: 0.3108\n",
            "Epoch 55/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9033 - loss: 0.2619 - val_accuracy: 0.8855 - val_loss: 0.3207\n",
            "Epoch 56/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9044 - loss: 0.2619 - val_accuracy: 0.8876 - val_loss: 0.3146\n",
            "Epoch 57/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9050 - loss: 0.2612 - val_accuracy: 0.8784 - val_loss: 0.3412\n",
            "Epoch 58/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9073 - loss: 0.2576 - val_accuracy: 0.8894 - val_loss: 0.3153\n",
            "Epoch 59/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9065 - loss: 0.2540 - val_accuracy: 0.8879 - val_loss: 0.3146\n",
            "Epoch 60/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9084 - loss: 0.2509 - val_accuracy: 0.8906 - val_loss: 0.3094\n",
            "Epoch 61/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9099 - loss: 0.2466 - val_accuracy: 0.8879 - val_loss: 0.3173\n",
            "Epoch 62/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9065 - loss: 0.2540 - val_accuracy: 0.8894 - val_loss: 0.3113\n",
            "Epoch 63/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9082 - loss: 0.2513 - val_accuracy: 0.8918 - val_loss: 0.3057\n",
            "Epoch 64/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9097 - loss: 0.2507 - val_accuracy: 0.8873 - val_loss: 0.3167\n",
            "Epoch 65/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9021 - loss: 0.2602 - val_accuracy: 0.8877 - val_loss: 0.3122\n",
            "Epoch 66/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9115 - loss: 0.2398 - val_accuracy: 0.8903 - val_loss: 0.3044\n",
            "Epoch 67/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9095 - loss: 0.2506 - val_accuracy: 0.8940 - val_loss: 0.3016\n",
            "Epoch 68/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9114 - loss: 0.2428 - val_accuracy: 0.8854 - val_loss: 0.3139\n",
            "Epoch 69/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9127 - loss: 0.2379 - val_accuracy: 0.8921 - val_loss: 0.3050\n",
            "Epoch 70/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9108 - loss: 0.2404 - val_accuracy: 0.8917 - val_loss: 0.3060\n",
            "Epoch 71/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9125 - loss: 0.2393 - val_accuracy: 0.8929 - val_loss: 0.3031\n",
            "Epoch 72/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9117 - loss: 0.2391 - val_accuracy: 0.8919 - val_loss: 0.3099\n",
            "Epoch 73/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9109 - loss: 0.2431 - val_accuracy: 0.8923 - val_loss: 0.3078\n",
            "Epoch 74/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9160 - loss: 0.2304 - val_accuracy: 0.8887 - val_loss: 0.3102\n",
            "Epoch 75/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9137 - loss: 0.2334 - val_accuracy: 0.8872 - val_loss: 0.3105\n",
            "Epoch 76/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9115 - loss: 0.2398 - val_accuracy: 0.8969 - val_loss: 0.2967\n",
            "Epoch 77/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9135 - loss: 0.2335 - val_accuracy: 0.8936 - val_loss: 0.3017\n",
            "Epoch 78/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9150 - loss: 0.2324 - val_accuracy: 0.8931 - val_loss: 0.3027\n",
            "Epoch 79/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9154 - loss: 0.2306 - val_accuracy: 0.8947 - val_loss: 0.3017\n",
            "Epoch 80/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9164 - loss: 0.2273 - val_accuracy: 0.8936 - val_loss: 0.3041\n",
            "Epoch 81/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9137 - loss: 0.2345 - val_accuracy: 0.8936 - val_loss: 0.2961\n",
            "Epoch 82/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9165 - loss: 0.2266 - val_accuracy: 0.8925 - val_loss: 0.3040\n",
            "Epoch 83/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9150 - loss: 0.2277 - val_accuracy: 0.8929 - val_loss: 0.3013\n",
            "Epoch 84/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9197 - loss: 0.2185 - val_accuracy: 0.8955 - val_loss: 0.2998\n",
            "Epoch 85/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9189 - loss: 0.2183 - val_accuracy: 0.8928 - val_loss: 0.3045\n",
            "Epoch 86/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9193 - loss: 0.2213 - val_accuracy: 0.8932 - val_loss: 0.3036\n",
            "Epoch 87/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9189 - loss: 0.2177 - val_accuracy: 0.8948 - val_loss: 0.2956\n",
            "Epoch 88/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9197 - loss: 0.2173 - val_accuracy: 0.8898 - val_loss: 0.3122\n",
            "Epoch 89/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9171 - loss: 0.2241 - val_accuracy: 0.8978 - val_loss: 0.2949\n",
            "Epoch 90/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9218 - loss: 0.2133 - val_accuracy: 0.8959 - val_loss: 0.2947\n",
            "Epoch 91/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9217 - loss: 0.2113 - val_accuracy: 0.8951 - val_loss: 0.2976\n",
            "Epoch 92/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9212 - loss: 0.2132 - val_accuracy: 0.8962 - val_loss: 0.2976\n",
            "Epoch 93/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9207 - loss: 0.2100 - val_accuracy: 0.8973 - val_loss: 0.2963\n",
            "Epoch 94/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9227 - loss: 0.2093 - val_accuracy: 0.8968 - val_loss: 0.2980\n",
            "Epoch 95/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9220 - loss: 0.2138 - val_accuracy: 0.8945 - val_loss: 0.3044\n",
            "Epoch 96/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9221 - loss: 0.2093 - val_accuracy: 0.8959 - val_loss: 0.2976\n",
            "Epoch 97/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9213 - loss: 0.2121 - val_accuracy: 0.8988 - val_loss: 0.2937\n",
            "Epoch 98/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9245 - loss: 0.2069 - val_accuracy: 0.8907 - val_loss: 0.3125\n",
            "Epoch 99/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9207 - loss: 0.2126 - val_accuracy: 0.8813 - val_loss: 0.3324\n",
            "Epoch 100/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9154 - loss: 0.2220 - val_accuracy: 0.8989 - val_loss: 0.2942\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7dea90caea90>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# TODO: Compile and fit your model\n",
        "import os\n",
        "\n",
        "# os.environ['KMP_DUPLICATE_LIB_OK']='True' #https://stackoverflow.com/questions/53014306/error-15-initializing-libiomp5-dylib-but-found-libiomp5-dylib-already-initial\n",
        "\n",
        "\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "\n",
        "model = lenet5()\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Define now our callbacks\n",
        "# callbacks = [EarlyStopping(monitor='val_loss', patience=10), TensorBoard(log_dir='./keras-logs', histogram_freq=0, write_graph=True, write_images=True)]\n",
        "callbacks = [EarlyStopping(monitor='val_loss', patience=10)]\n",
        "\n",
        "# Finally fit the model\n",
        "model.fit(x=X_train_norm, y=y_train_cat, validation_data=(X_test_norm, y_test_cat), epochs=100, batch_size=2048, callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rf-SqjjOyO8q"
      },
      "source": [
        "Have a look at the tensorboard and see if it gives a deeper understanding of your model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k2FTj7TSyO8q"
      },
      "source": [
        "Compute then the accuracy of your model. Is it better than a regular MLP used before?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rPjJoMQZyO8q",
        "outputId": "66e89eb7-e0fc-4d01-8bc9-5a4b1a628181"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
            "accuracy on train with CNN: 0.9263666666666667\n",
            "accuracy on test with CNN: 0.8989\n"
          ]
        }
      ],
      "source": [
        "# TODO: Compute the accuracy of your model\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "batch_size = 1024\n",
        "y_pred_train = to_categorical(model.predict(X_train_norm, batch_size=batch_size).argmax(axis=1), num_classes=10)\n",
        "y_pred_test = to_categorical(model.predict(X_test_norm, batch_size=batch_size).argmax(axis=1), num_classes=10)\n",
        "\n",
        "print('accuracy on train with CNN:', accuracy_score(y_pred_train, y_train_cat))\n",
        "print('accuracy on test with CNN:', accuracy_score(y_pred_test, y_test_cat))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1vulsgHiyO8q"
      },
      "source": [
        "We will now add image augmentation to improve our results, especially we will try to reduce overfitting this way.\n",
        "\n",
        "To do so, you can use `ImageDataGenerator` from Keras that makes all the work for you (including rescaling), with the following parameter:\n",
        "* `horizontal_flip=True`\n",
        "\n",
        "For more info about how the `ImageDataGenerator` works, you can check out [this article](https://www.pyimagesearch.com/2019/07/08/keras-imagedatagenerator-and-data-augmentation/).\n",
        "\n",
        "Begin by creating an object `ImageDataGenerator` with this parameter."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-08-19T11:58:37.442182Z",
          "start_time": "2020-08-19T11:58:37.438397Z"
        },
        "id": "pas-fMSIyO8q"
      },
      "outputs": [],
      "source": [
        "# TODO: Instantiate an ImageDataGenerator object\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator(horizontal_flip=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7nCnu9syO8r"
      },
      "source": [
        "Finally, you can train your model using this generator, with the method `fit_generator` of your model and the method `flow` of your `ImageDataGenerator`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zt6wXa3IyO8r",
        "outputId": "abeac9f4-046c-4438-bda0-95a79370b2c3",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 103ms/step - accuracy: 0.8334 - loss: 0.6411 - val_accuracy: 0.8877 - val_loss: 0.3201\n",
            "Epoch 2/100\n",
            "\u001b[1m 1/58\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8818 - loss: 0.3299"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/epoch_iterator.py:107: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self._interrupted_warning()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8818 - loss: 0.3299 - val_accuracy: 0.8881 - val_loss: 0.3175\n",
            "Epoch 3/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 61ms/step - accuracy: 0.8970 - loss: 0.2862 - val_accuracy: 0.8899 - val_loss: 0.3110\n",
            "Epoch 4/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8926 - loss: 0.3001 - val_accuracy: 0.8875 - val_loss: 0.3132\n",
            "Epoch 5/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 59ms/step - accuracy: 0.8980 - loss: 0.2777 - val_accuracy: 0.8941 - val_loss: 0.2982\n",
            "Epoch 6/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9150 - loss: 0.2230 - val_accuracy: 0.8933 - val_loss: 0.3023\n",
            "Epoch 7/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.9036 - loss: 0.2639 - val_accuracy: 0.8890 - val_loss: 0.3151\n",
            "Epoch 8/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8799 - loss: 0.2798 - val_accuracy: 0.8856 - val_loss: 0.3209\n",
            "Epoch 9/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - accuracy: 0.8986 - loss: 0.2731 - val_accuracy: 0.8959 - val_loss: 0.2992\n",
            "Epoch 10/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9180 - loss: 0.2269 - val_accuracy: 0.8951 - val_loss: 0.2965\n",
            "Epoch 11/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 54ms/step - accuracy: 0.9052 - loss: 0.2570 - val_accuracy: 0.8927 - val_loss: 0.3039\n",
            "Epoch 12/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9072 - loss: 0.2640 - val_accuracy: 0.8919 - val_loss: 0.3043\n",
            "Epoch 13/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 60ms/step - accuracy: 0.9072 - loss: 0.2503 - val_accuracy: 0.8958 - val_loss: 0.2959\n",
            "Epoch 14/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9141 - loss: 0.2310 - val_accuracy: 0.8957 - val_loss: 0.2983\n",
            "Epoch 15/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.9091 - loss: 0.2437 - val_accuracy: 0.8957 - val_loss: 0.2955\n",
            "Epoch 16/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9062 - loss: 0.2341 - val_accuracy: 0.8944 - val_loss: 0.2952\n",
            "Epoch 17/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.9101 - loss: 0.2450 - val_accuracy: 0.8940 - val_loss: 0.2996\n",
            "Epoch 18/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9160 - loss: 0.2471 - val_accuracy: 0.8948 - val_loss: 0.2961\n",
            "Epoch 19/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 51ms/step - accuracy: 0.9121 - loss: 0.2419 - val_accuracy: 0.8951 - val_loss: 0.2975\n",
            "Epoch 20/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9121 - loss: 0.2442 - val_accuracy: 0.8962 - val_loss: 0.2936\n",
            "Epoch 21/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.9115 - loss: 0.2370 - val_accuracy: 0.8952 - val_loss: 0.2999\n",
            "Epoch 22/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9199 - loss: 0.2504 - val_accuracy: 0.8961 - val_loss: 0.2988\n",
            "Epoch 23/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 59ms/step - accuracy: 0.9127 - loss: 0.2373 - val_accuracy: 0.8876 - val_loss: 0.3069\n",
            "Epoch 24/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9238 - loss: 0.2150 - val_accuracy: 0.8853 - val_loss: 0.3144\n",
            "Epoch 25/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - accuracy: 0.9124 - loss: 0.2396 - val_accuracy: 0.8956 - val_loss: 0.2960\n",
            "Epoch 26/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9150 - loss: 0.2343 - val_accuracy: 0.8963 - val_loss: 0.2946\n",
            "Epoch 27/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 53ms/step - accuracy: 0.9104 - loss: 0.2377 - val_accuracy: 0.8986 - val_loss: 0.2883\n",
            "Epoch 28/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9199 - loss: 0.2274 - val_accuracy: 0.8968 - val_loss: 0.2968\n",
            "Epoch 29/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 60ms/step - accuracy: 0.9142 - loss: 0.2286 - val_accuracy: 0.8979 - val_loss: 0.2890\n",
            "Epoch 30/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8994 - loss: 0.2673 - val_accuracy: 0.8986 - val_loss: 0.2879\n",
            "Epoch 31/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 61ms/step - accuracy: 0.9148 - loss: 0.2295 - val_accuracy: 0.8965 - val_loss: 0.2925\n",
            "Epoch 32/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9160 - loss: 0.2164 - val_accuracy: 0.8920 - val_loss: 0.3054\n",
            "Epoch 33/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 0.9124 - loss: 0.2348 - val_accuracy: 0.8997 - val_loss: 0.2857\n",
            "Epoch 34/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9062 - loss: 0.2369 - val_accuracy: 0.8983 - val_loss: 0.2883\n",
            "Epoch 35/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.9164 - loss: 0.2239 - val_accuracy: 0.8969 - val_loss: 0.2887\n",
            "Epoch 36/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9141 - loss: 0.2509 - val_accuracy: 0.9000 - val_loss: 0.2849\n",
            "Epoch 37/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - accuracy: 0.9184 - loss: 0.2199 - val_accuracy: 0.9002 - val_loss: 0.2882\n",
            "Epoch 38/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9150 - loss: 0.2324 - val_accuracy: 0.8975 - val_loss: 0.2906\n",
            "Epoch 39/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - accuracy: 0.9160 - loss: 0.2272 - val_accuracy: 0.8983 - val_loss: 0.2883\n",
            "Epoch 40/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9248 - loss: 0.1931 - val_accuracy: 0.8961 - val_loss: 0.2892\n",
            "Epoch 41/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 59ms/step - accuracy: 0.9200 - loss: 0.2177 - val_accuracy: 0.9010 - val_loss: 0.2827\n",
            "Epoch 42/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9248 - loss: 0.2126 - val_accuracy: 0.9000 - val_loss: 0.2836\n",
            "Epoch 43/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 49ms/step - accuracy: 0.9179 - loss: 0.2176 - val_accuracy: 0.9008 - val_loss: 0.2839\n",
            "Epoch 44/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9180 - loss: 0.2113 - val_accuracy: 0.9005 - val_loss: 0.2844\n",
            "Epoch 45/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.9191 - loss: 0.2136 - val_accuracy: 0.8974 - val_loss: 0.2947\n",
            "Epoch 46/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9268 - loss: 0.1968 - val_accuracy: 0.8965 - val_loss: 0.2929\n",
            "Epoch 47/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 60ms/step - accuracy: 0.9195 - loss: 0.2165 - val_accuracy: 0.9040 - val_loss: 0.2854\n",
            "Epoch 48/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9170 - loss: 0.2251 - val_accuracy: 0.9030 - val_loss: 0.2831\n",
            "Epoch 49/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 0.9193 - loss: 0.2134 - val_accuracy: 0.9017 - val_loss: 0.2818\n",
            "Epoch 50/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9111 - loss: 0.2398 - val_accuracy: 0.9016 - val_loss: 0.2848\n",
            "Epoch 51/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - accuracy: 0.9232 - loss: 0.2086 - val_accuracy: 0.8997 - val_loss: 0.2898\n",
            "Epoch 52/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9092 - loss: 0.2374 - val_accuracy: 0.9009 - val_loss: 0.2858\n",
            "Epoch 53/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - accuracy: 0.9211 - loss: 0.2126 - val_accuracy: 0.9009 - val_loss: 0.2868\n",
            "Epoch 54/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9238 - loss: 0.2158 - val_accuracy: 0.9008 - val_loss: 0.2857\n",
            "Epoch 55/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.9222 - loss: 0.2066 - val_accuracy: 0.9007 - val_loss: 0.2864\n",
            "Epoch 56/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9248 - loss: 0.2355 - val_accuracy: 0.8989 - val_loss: 0.2880\n",
            "Epoch 57/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 60ms/step - accuracy: 0.9244 - loss: 0.2050 - val_accuracy: 0.9029 - val_loss: 0.2811\n",
            "Epoch 58/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9268 - loss: 0.1981 - val_accuracy: 0.9022 - val_loss: 0.2848\n",
            "Epoch 59/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 60ms/step - accuracy: 0.9233 - loss: 0.2073 - val_accuracy: 0.9009 - val_loss: 0.2889\n",
            "Epoch 60/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9199 - loss: 0.2190 - val_accuracy: 0.9044 - val_loss: 0.2861\n",
            "Epoch 61/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 49ms/step - accuracy: 0.9276 - loss: 0.2011 - val_accuracy: 0.9008 - val_loss: 0.2868\n",
            "Epoch 62/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9209 - loss: 0.2154 - val_accuracy: 0.8996 - val_loss: 0.2859\n",
            "Epoch 63/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.9216 - loss: 0.2080 - val_accuracy: 0.9042 - val_loss: 0.2831\n",
            "Epoch 64/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9268 - loss: 0.2076 - val_accuracy: 0.9031 - val_loss: 0.2865\n",
            "Epoch 65/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 56ms/step - accuracy: 0.9258 - loss: 0.2008 - val_accuracy: 0.8982 - val_loss: 0.2947\n",
            "Epoch 66/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9268 - loss: 0.2014 - val_accuracy: 0.9001 - val_loss: 0.2932\n",
            "Epoch 67/100\n",
            "\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 50ms/step - accuracy: 0.9237 - loss: 0.2037 - val_accuracy: 0.9016 - val_loss: 0.2846\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7dea605f1f90>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# TODO: train your model\n",
        "batch_size = 1024\n",
        "model.fit(datagen.flow(X_train_norm, y_train_cat, batch_size=batch_size),\n",
        "                    validation_data=(X_test_norm, y_test_cat), callbacks=callbacks,\n",
        "                    steps_per_epoch=len(X_train_norm) // batch_size, epochs=100)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ehnbWpy_DtO7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Not sure why it only got to 67 epochs, I tried running this cell multiple times and it ran for a different number of epochs each time. Meant to be 100 epochs."
      ],
      "metadata": {
        "id": "PtTrMyQBDuwt"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NuzFke8pyO8r"
      },
      "source": [
        "Recompute the accuracy of your model, does it improve your performances with data augmentation?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jsTm86tuyO8r",
        "outputId": "c2a79cc8-44d9-4a65-9b5b-430e4aaf1307"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m59/59\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step \n",
            "accuracy on train with CNN: 0.9308666666666666\n",
            "accuracy on test with CNN: 0.9016\n"
          ]
        }
      ],
      "source": [
        "# TODO: Compute the accuracy of your model\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "batch_size=1024\n",
        "y_pred_train = to_categorical(model.predict(X_train_norm, batch_size=batch_size).argmax(axis=1), num_classes=10)\n",
        "y_pred_test = to_categorical(model.predict(X_test_norm, batch_size=batch_size).argmax(axis=1), num_classes=10)\n",
        "\n",
        "print('accuracy on train with CNN:', accuracy_score(y_pred_train, y_train_cat))\n",
        "print('accuracy on test with CNN:', accuracy_score(y_pred_test, y_test_cat))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jOzkdGf7yO8s"
      },
      "source": [
        "You can now try to improve even more your results. For example, add more parameters to your `ImageDataGenerator`, play with some hyperparameters, and so on..."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}