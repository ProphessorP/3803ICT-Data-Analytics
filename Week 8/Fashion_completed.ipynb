{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k4-KVQwtUICI"
      },
      "source": [
        "# Image Classification by MLP - Fashion MNIST"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aq_qZieMUICJ"
      },
      "source": [
        "In this exercise, we will try to use a neural network on a simple classification task: classifying images of clothes into 10 classes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-HxObM6UICJ"
      },
      "source": [
        "We will first download the data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XIPD6TGEUICJ",
        "outputId": "d1c0225d-f80d-4639-f0c8-9cf394589f8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "\u001b[1m29515/29515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "\u001b[1m26421880/26421880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "\u001b[1m5148/5148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "\u001b[1m4422102/4422102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "\n",
        "#TODO: load dataset\n",
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "#TODO: Resample the dataset if needed\n",
        "#X_train = ...\n",
        "#y_train = ...\n",
        "#X_test = ...\n",
        "#y_test = ...\n",
        "\n",
        "X_train.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nsMubhcsUICK"
      },
      "source": [
        "This dataset contains 10 classes:\n",
        "* 0:\tT-shirt/top\n",
        "* 1:\tTrouser\n",
        "* 2:\tPullover\n",
        "* 3:\tDress\n",
        "* 4:\tCoat\n",
        "* 5:\tSandal\n",
        "* 6:\tShirt\n",
        "* 7:\tSneaker\n",
        "* 8:\tBag\n",
        "* 9:\tAnkle boot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-X-CHj5bUICK"
      },
      "source": [
        "Now begin by exploring the data. Try to display some images with the associated label."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "H1GB05ObUICK",
        "outputId": "147df3be-1f36-45ea-d21a-69ace4dcc2c5"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGzCAYAAABpdMNsAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAJKNJREFUeJzt3XtsVHX6x/HPtLTTIr1YS29rgYLcFOhGFLaigNIANUFRdgU1GzAKQVtWZFmVVbns/pK6mCiRIJrNLvWGAi5gNIhRkLK64C4oIq4gZauUS8sltgOlnZbO9/cHcXSkXM5hOt9e3q9kEmbmPP0+c3raD2cuTz3GGCMAACIsynYDAICOiQACAFhBAAEArCCAAABWEEAAACsIIACAFQQQAMAKAggAYAUBBACwggACwqCkpEQej0fffvtt8LaRI0dq5MiR1noCWjsCCABgBQEEALCCAAI6oEAgoPr6etttoIMjgNAhzZ8/Xx6PR7t379Zdd92lxMREXXHFFXr44YeDv5i//fZbeTwelZSUnFXv8Xg0f/58x+seOXJE999/v9LT0xUXF6fc3Fy9/PLLwfsbGxuVkpKi++6776xan8+nuLg4zZ49O3ib3+/XvHnzdNVVV8nr9So7O1uPPvqo/H7/Wf0WFRXp9ddf1zXXXCOv16v169c77h8Ip062GwBsuuuuu9SjRw8VFxdr69atev755/X999/rlVdeCftadXV1GjlypMrKylRUVKScnBytWrVKU6ZMUXV1tR5++GHFxMTojjvu0OrVq/XSSy8pNjY2WL927Vr5/X5NmjRJ0pmzmNtuu00ff/yxpk2bpv79++vLL7/Uc889p2+++UZr164NWX/jxo1auXKlioqKlJqaqh49eoT9MQKOGKADmjdvnpFkbrvttpDbH3roISPJfPHFF6a8vNxIMsuWLTurXpKZN29e8PqyZcuMJFNeXh68bcSIEWbEiBHB64sWLTKSzGuvvRa8raGhweTl5ZkuXboYn89njDHm/fffN5LMO++8E7Lmrbfeanr27Bm8/uqrr5qoqCjzz3/+M2S7F1980Ugyn3zySUi/UVFR5quvvrrgvgEihafg0KEVFhaGXJ8xY4Ykad26dWFfa926dcrIyNDdd98dvC0mJka/+93vdPLkSZWWlkqSbrnlFqWmpmrFihXB7b7//nt98MEHmjhxYvC2VatWqX///urXr5+OHTsWvNxyyy2SpI8++ihk/REjRujqq68O++MC3OIpOHRovXv3Drneq1cvRUVFhXyeJ1y+++479e7dW1FRof/v69+/f/B+SerUqZMmTJig5cuXy+/3y+v1avXq1WpsbAwJoL179+rrr79W165dm13vyJEjIddzcnLC+XCAS0YAAT/h8Xia/fdPNTU1tXgfkyZN0ksvvaT33ntP48eP18qVK9WvXz/l5uYGtwkEAho4cKCeffbZZr9GdnZ2yPX4+PgW7RlwigBCh7Z3796QM4OysjIFAgH16NFDl19+uSSpuro6pOaHMxWnunfvrp07dyoQCIScBe3evTt4/w+GDx+uzMxMrVixQjfeeKM2btyoJ554IuTr9erVS1988YVGjRp1zrAEWjNeA0KHtmTJkpDrixcvliQVFBQoMTFRqamp2rx5c8g2L7zwgqu1br31VlVWVoa8tnP69GktXrxYXbp00YgRI4K3R0VF6de//rXeeecdvfrqqzp9+nTI02/SmXfwHTx4UH/961/PWquurk61tbWu+gQihTMgdGjl5eW67bbbNHbsWG3ZskWvvfaa7rnnnuBTXQ888ICefvppPfDAA7ruuuu0efNmffPNN67WmjZtml566SVNmTJF27dvV48ePfTWW2/pk08+0aJFi5SQkBCy/cSJE7V48WLNmzdPAwcODL5W9IPf/va3WrlypaZPn66PPvpIw4YNU1NTk3bv3q2VK1fq/fff13XXXeduxwARQAChQ1uxYoXmzp2rxx9/XJ06dVJRUZGeeeaZ4P1z587V0aNH9dZbb2nlypUqKCjQe++9p7S0NMdrxcfHa9OmTXr88cf18ssvy+fzqW/fvlq2bJmmTJly1vY33HCDsrOzVVFRcdbZj3TmLGnt2rV67rnn9Morr2jNmjXq3LmzevbsqYcfflh9+vRx3CMQSR5jjLHdBBBp8+fP14IFC3T06FGlpqbabgfokHgNCABgBQEEALCCAAIAWMFrQAAAKzgDAgBYQQABAKxodZ8DCgQCOnTokBISEhgvAgBtkDFGJ06cUFZW1lnDd3+q1QXQoUOHzhqiCABoeyoqKnTllVee8/5WF0A/jCOpqKhQYmKi5W7QGvz8z0tfjK1bt7pa64svvnBcc/DgQcc133//veOalJQUxzU/HXDqxJAhQxzXDB482NVaaH98Pp+ys7PPGi/1cy0WQEuWLNEzzzyjyspK5ebmavHixRd1UP/wtFtiYiIBBEnuAuiyyy5ztVZcXJzjGq/X67jmp39quyXXcfN4JKlLly6Oa/h5xc9d6GWUFnkTwooVKzRr1izNmzdPn332mXJzczVmzJiz/kAWAKDjapEAevbZZzV16lTdd999uvrqq/Xiiy+qc+fO+vvf/94SywEA2qCwB1BDQ4O2b9+u/Pz8HxeJilJ+fr62bNly1vZ+v18+ny/kAgBo/8IeQMeOHVNTU5PS09NDbk9PT1dlZeVZ2xcXFyspKSl44R1wANAxWP8g6pw5c1RTUxO8VFRU2G4JABABYX8XXGpqqqKjo1VVVRVye1VVlTIyMs7a3uv1unp3DwCgbQv7GVBsbKwGDx6sDRs2BG8LBALasGGD8vLywr0cAKCNapHPAc2aNUuTJ0/WddddpyFDhmjRokWqra3Vfffd1xLLAQDaoBYJoIkTJ+ro0aOaO3euKisr9ctf/lLr168/640JAICOq9X9PSCfz6ekpCTV1NTwyWoXAoGA45rzDQsMt/79+zuucfMB5pMnTzqukdztv9OnT7taKxLcfm/dvC57vplf5/LTp+ovlpt3yjY2NjqukaSYmBhXdR3dxf4et/4uOABAx0QAAQCsIIAAAFYQQAAAKwggAIAVBBAAwAoCCABgBQEEALCCAAIAWEEAAQCsIIAAAFYQQAAAK1pkGjZwLt9//73jmujoaMc1KSkpjmskqb6+3nFNpAbAuhmMGRsb67hGcrfPjx075rjGzf52I5IDd3Hx+K4AAKwggAAAVhBAAAArCCAAgBUEEADACgIIAGAFAQQAsIIAAgBYQQABAKwggAAAVhBAAAArCCAAgBUEEADACqZhtzOtfepvWlqa45qDBw86rnE7Bbp3796OayoqKhzXuJk23dTU5Ljm9OnTjmskdxO+O3Vy/uukrq7OcQ3aj9b92woA0G4RQAAAKwggAIAVBBAAwAoCCABgBQEEALCCAAIAWEEAAQCsIIAAAFYQQAAAKwggAIAVBBAAwAqGkSKivvzyS8c1GRkZjms8Ho/jGkk6cOCA4xq/3++4xs0wUjfcDBWVJK/X67jm6NGjjmsGDRrkuMaNSO1vOMMZEADACgIIAGAFAQQAsIIAAgBYQQABAKwggAAAVhBAAAArCCAAgBUEEADACgIIAGAFAQQAsIIAAgBYwTBS6B//+IerutmzZzuuSUlJcVxTX1/vuOb06dOOayQpKsr5/8k6dYrMj5GbAasxMTGu1jLGOK7JzMx0XDN69GjHNU8++aTjmuHDhzuuQcvjDAgAYAUBBACwIuwBNH/+fHk8npBLv379wr0MAKCNa5Enr6+55hp9+OGHPy4SoefIAQBtR4skQ6dOnVz9FUsAQMfRIq8B7d27V1lZWerZs6fuvfde7d+//5zb+v1++Xy+kAsAoP0LewANHTpUJSUlWr9+vZYuXary8nLddNNNOnHiRLPbFxcXKykpKXjJzs4Od0sAgFYo7AFUUFCg3/zmNxo0aJDGjBmjdevWqbq6WitXrmx2+zlz5qimpiZ4qaioCHdLAIBWqMXfHZCcnKw+ffqorKys2fu9Xq+8Xm9LtwEAaGVa/HNAJ0+e1L59+1x9ShoA0H6FPYBmz56t0tJSffvtt/rXv/6lO+64Q9HR0br77rvDvRQAoA0L+1NwBw4c0N13363jx4+ra9euuvHGG7V161Z17do13EsBANowj3EzdbAF+Xw+JSUlqaamRomJibbbaXM+/vhjxzX5+fmu1oqLi3NcEx8f77jG7WBRN9ys5WZIaHR0dERq3PTmts7NINfa2lrHNW6G065fv95xjSSNGDHCVV1Hd7G/x5kFBwCwggACAFhBAAEArCCAAABWEEAAACsIIACAFQQQAMAKAggAYAUBBACwggACAFhBAAEArCCAAABWtPgfpENkPfHEE45r3A6s7NKli+OapqYmxzVuhly6fUxuBn66mecbqWGfbmcNu6lz871NTk52XHPs2DHHNTNmzHBcI0k7d+50VYeLwxkQAMAKAggAYAUBBACwggACAFhBAAEArCCAAABWEEAAACsIIACAFQQQAMAKAggAYAUBBACwggACAFhBAAEArGAadjvjZnpvbGysq7UaGhoc15w+fdpxTUxMjOMat9xO0Y4ENxOq3Uz3lqTa2lrHNXFxcY5r3BwP8fHxjmvq6uoc16DlcQYEALCCAAIAWEEAAQCsIIAAAFYQQAAAKwggAIAVBBAAwAoCCABgBQEEALCCAAIAWEEAAQCsIIAAAFYwjLSdqa6udlyTnJwc9j7OpVMn54dcax4QKrnrL1KPye/3u6rr37+/45rDhw87rgkEAo5r3AxYLSsrc1wjuRuW6uYY76g4AwIAWEEAAQCsIIAAAFYQQAAAKwggAIAVBBAAwAoCCABgBQEEALCCAAIAWEEAAQCsIIAAAFYQQAAAK5ia14odOHAgIut4vV5XdfX19Y5rYmJiHNe09mGkbhhjHNe42Q9uhmlKUlxcnOOapKQkxzVuBphG0v/+9z/HNX369GmBTtonzoAAAFYQQAAAKxwH0ObNmzVu3DhlZWXJ4/Fo7dq1IfcbYzR37lxlZmYqPj5e+fn52rt3b7j6BQC0E44DqLa2Vrm5uVqyZEmz9y9cuFDPP/+8XnzxRX366ae67LLLNGbMGFevFwAA2i/Hb0IoKChQQUFBs/cZY7Ro0SI9+eSTuv322yVJr7zyitLT07V27VpNmjTp0roFALQbYX0NqLy8XJWVlcrPzw/elpSUpKFDh2rLli3N1vj9fvl8vpALAKD9C2sAVVZWSpLS09NDbk9PTw/e93PFxcVKSkoKXrKzs8PZEgCglbL+Lrg5c+aopqYmeKmoqLDdEgAgAsIaQBkZGZKkqqqqkNurqqqC9/2c1+tVYmJiyAUA0P6FNYBycnKUkZGhDRs2BG/z+Xz69NNPlZeXF86lAABtnON3wZ08eVJlZWXB6+Xl5dqxY4dSUlLUrVs3zZw5U//3f/+n3r17KycnR0899ZSysrI0fvz4cPYNAGjjHAfQtm3bdPPNNwevz5o1S5I0efJklZSU6NFHH1Vtba2mTZum6upq3XjjjVq/fr2r2VIAgPbLY9xMRWxBPp9PSUlJqqmp6fCvB53rrevnc8MNNziuOdfrcxdy4sQJxzXx8fGOa9wM4XQ7wDRSg09b2Y/dWfx+v+MaNz+vbo6h2NhYxzVHjhxxXCNJ69atc1xzrs9JdiQX+3vc+rvgAAAdEwEEALCCAAIAWEEAAQCsIIAAAFYQQAAAKwggAIAVBBAAwAoCCABgBQEEALCCAAIAWEEAAQCsIIAAAFY4/nMMiJzvvvvOdgvn1djY6LgmJiYmIjWBQMBxjRS5adiRmvDtdj907tzZVZ1TtbW1jmu8Xm8LdNK8Q4cORWytjogzIACAFQQQAMAKAggAYAUBBACwggACAFhBAAEArCCAAABWEEAAACsIIACAFQQQAMAKAggAYAUBBACwgmGkrVh1dXVE1nE7sHLUqFGOaz788EPHNcnJyY5rIilSA0zdiIpy939MY4zjGjeDRfPy8hzXfPnll45r3HLzmHDxOAMCAFhBAAEArCCAAABWEEAAACsIIACAFQQQAMAKAggAYAUBBACwggACAFhBAAEArCCAAABWEEAAACsYRtqK1dXVRWSdhoYGV3Xjxo1zXPPee+85rnEzGLM1Dwh1y81+cDuMNCYmxnGNm+P17rvvdlzzn//8x3GNW42NjRFbqyPiDAgAYAUBBACwggACAFhBAAEArCCAAABWEEAAACsIIACAFQQQAMAKAggAYAUBBACwggACAFhBAAEArGAYaSt24sSJiKxTX1/vqu7qq692XONmOGZTU5PjmujoaMc1krshppEalhrJAauBQMBxjZuhtn379nVc4/Z4dePUqVMRW6sj4gwIAGAFAQQAsMJxAG3evFnjxo1TVlaWPB6P1q5dG3L/lClT5PF4Qi5jx44NV78AgHbCcQDV1tYqNzdXS5YsOec2Y8eO1eHDh4OXN95445KaBAC0P47fhFBQUKCCgoLzbuP1epWRkeG6KQBA+9cirwFt2rRJaWlp6tu3rx588EEdP378nNv6/X75fL6QCwCg/Qt7AI0dO1avvPKKNmzYoL/85S8qLS1VQUHBOd9KW1xcrKSkpOAlOzs73C0BAFqhsH8OaNKkScF/Dxw4UIMGDVKvXr20adMmjRo16qzt58yZo1mzZgWv+3w+QggAOoAWfxt2z549lZqaqrKysmbv93q9SkxMDLkAANq/Fg+gAwcO6Pjx48rMzGzppQAAbYjjp+BOnjwZcjZTXl6uHTt2KCUlRSkpKVqwYIEmTJigjIwM7du3T48++qiuuuoqjRkzJqyNAwDaNscBtG3bNt18883B6z+8fjN58mQtXbpUO3fu1Msvv6zq6mplZWVp9OjR+vOf/yyv1xu+rgEAbZ7jABo5cuR5hy++//77l9QQflRTUxORddwO7jx9+rTjGjdDLt3052Ydyd2w1EgNCY3kANNIfZ+6du3quCaSamtrbbfQrjELDgBgBQEEALCCAAIAWEEAAQCsIIAAAFYQQAAAKwggAIAVBBAAwAoCCABgBQEEALCCAAIAWEEAAQCsIIAAAFaE/U9yI3xOnToVkXUSEhJc1dXV1YW5k+ZFatq0W276czN12w23k86bmpoc17iZju5mP8TGxjqu8fv9jmsupQ4XhzMgAIAVBBAAwAoCCABgBQEEALCCAAIAWEEAAQCsIIAAAFYQQAAAKwggAIAVBBAAwAoCCABgBQEEALCCYaStWG1tbUTW6dKli6s6Y0yYO2mem4GaboZptkdu94ObgZ/19fWOa2pqahzXRHIYqZvHhIvHGRAAwAoCCABgBQEEALCCAAIAWEEAAQCsIIAAAFYQQAAAKwggAIAVBBAAwAoCCABgBQEEALCCAAIAWMEw0lassbExIut07drVVV18fHyYO2lep07OD9OGhoYW6KR5gUAgIut4PJ6IrCNJUVGR+b+pz+dzXHP55Zc7rjlx4oTjGsn9EFNcHM6AAABWEEAAACsIIACAFQQQAMAKAggAYAUBBACwggACAFhBAAEArCCAAABWEEAAACsIIACAFQQQAMAKhpG2YpEaPpmWluaq7quvvgpzJ80zxjiuidQwTbfcPCY3x4ObdS6lzqmjR486rklJSXFcs3//fsc1ktTU1OSqDhendf+UAgDaLQIIAGCFowAqLi7W9ddfr4SEBKWlpWn8+PHas2dPyDb19fUqLCzUFVdcoS5dumjChAmqqqoKa9MAgLbPUQCVlpaqsLBQW7du1QcffKDGxkaNHj1atbW1wW0eeeQRvfPOO1q1apVKS0t16NAh3XnnnWFvHADQtjl6E8L69etDrpeUlCgtLU3bt2/X8OHDVVNTo7/97W9avny5brnlFknSsmXL1L9/f23dulW/+tWvwtc5AKBNu6TXgGpqaiT9+K6U7du3q7GxUfn5+cFt+vXrp27dumnLli3Nfg2/3y+fzxdyAQC0f64DKBAIaObMmRo2bJgGDBggSaqsrFRsbKySk5NDtk1PT1dlZWWzX6e4uFhJSUnBS3Z2ttuWAABtiOsAKiws1K5du/Tmm29eUgNz5sxRTU1N8FJRUXFJXw8A0Da4+iBqUVGR3n33XW3evFlXXnll8PaMjAw1NDSouro65CyoqqpKGRkZzX4tr9crr9frpg0AQBvm6AzIGKOioiKtWbNGGzduVE5OTsj9gwcPVkxMjDZs2BC8bc+ePdq/f7/y8vLC0zEAoF1wdAZUWFio5cuX6+2331ZCQkLwdZ2kpCTFx8crKSlJ999/v2bNmqWUlBQlJiZqxowZysvL4x1wAIAQjgJo6dKlkqSRI0eG3L5s2TJNmTJFkvTcc88pKipKEyZMkN/v15gxY/TCCy+EpVkAQPvhKIAuZkBhXFyclixZoiVLlrhuCmdEahBi586dXdXt3r07zJ00LxAIRKRGcjfE1M1arXkd6czHI5zq1Mn5S8rr1q1zXBMXF+e4xi23xxEuDrPgAABWEEAAACsIIACAFQQQAMAKAggAYAUBBACwggACAFhBAAEArCCAAABWEEAAACsIIACAFQQQAMAKAggAYIWrv4iKyGhsbIzIOm4n/kZqGvbFTGH/uejo6Iit5WYKtJsp1W4ek9tp2G7+SvHJkycd1/h8Psc1bqe3u+HmeMDF4wwIAGAFAQQAsIIAAgBYQQABAKwggAAAVhBAAAArCCAAgBUEEADACgIIAGAFAQQAsIIAAgBYQQABAKxgGClUX1/vqu7AgQOOa+Lj4x3XuBmWGskhkm6HuUZCU1NTxNZyMyzVzTDSxMRExzVuNTQ0RGytjogzIACAFQQQAMAKAggAYAUBBACwggACAFhBAAEArCCAAABWEEAAACsIIACAFQQQAMAKAggAYAUBBACwgmGkrVikBkm6GRAqSXFxcRGpiYmJcVzjdkBoVFRk/k/m8Xgc17g5Htw+HjfDXN18nzp1cv4ryM3QU7dOnjwZsbU6Is6AAABWEEAAACsIIACAFQQQAMAKAggAYAUBBACwggACAFhBAAEArCCAAABWEEAAACsIIACAFQQQAMAKhpG2Yn369InIOr1793ZVd/DgQcc1tbW1jmvq6uoc17gZ9ilFbgCs2/6ccvt43PTnZvDpoUOHHNdce+21jmsuu+wyxzWS1K1bN1d1uDicAQEArCCAAABWOAqg4uJiXX/99UpISFBaWprGjx+vPXv2hGwzcuRIeTyekMv06dPD2jQAoO1zFEClpaUqLCzU1q1b9cEHH6ixsVGjR48+63n9qVOn6vDhw8HLwoULw9o0AKDtc/QmhPXr14dcLykpUVpamrZv367hw4cHb+/cubMyMjLC0yEAoF26pNeAampqJEkpKSkht7/++utKTU3VgAEDNGfOHJ06deqcX8Pv98vn84VcAADtn+u3YQcCAc2cOVPDhg3TgAEDgrffc8896t69u7KysrRz50499thj2rNnj1avXt3s1ykuLtaCBQvctgEAaKNcB1BhYaF27dqljz/+OOT2adOmBf89cOBAZWZmatSoUdq3b5969ep11teZM2eOZs2aFbzu8/mUnZ3tti0AQBvhKoCKior07rvvavPmzbryyivPu+3QoUMlSWVlZc0GkNfrldfrddMGAKANcxRAxhjNmDFDa9as0aZNm5STk3PBmh07dkiSMjMzXTUIAGifHAVQYWGhli9frrffflsJCQmqrKyUJCUlJSk+Pl779u3T8uXLdeutt+qKK67Qzp079cgjj2j48OEaNGhQizwAAEDb5CiAli5dKunMh01/atmyZZoyZYpiY2P14YcfatGiRaqtrVV2drYmTJigJ598MmwNAwDaB8dPwZ1Pdna2SktLL6khAEDHwDTsViwrKysi6yQkJLiqc/Nh408++cRxTWxsrOMat9OmL/SfrHDVuOFmnejoaFdruXljUHV1teOaG264wXGNm+PO7/c7rpGkvn37uqrDxWEYKQDACgIIAGAFAQQAsIIAAgBYQQABAKwggAAAVhBAAAArCCAAgBUEEADACgIIAGAFAQQAsIIAAgBYwTDSVqxz584RWadr166u6lauXBnmToALe+qppyK2VkxMTMTW6og4AwIAWEEAAQCsIIAAAFYQQAAAKwggAIAVBBAAwAoCCABgBQEEALCCAAIAWEEAAQCsIIAAAFa0ullwxhhJks/ns9yJfXV1da16Hb5HsMHv9zuu+eH3ilNufjb4ufhxH1xov3uM2+9MCzlw4ICys7NttwEAuEQVFRW68sorz3l/qwugQCCgQ4cOKSEhQR6PJ+Q+n8+n7OxsVVRUKDEx0VKH9rEfzmA/nMF+OIP9cEZr2A/GGJ04cUJZWVmKijr3Kz2t7im4qKio8yamJCUmJnboA+wH7Icz2A9nsB/OYD+cYXs/JCUlXXAb3oQAALCCAAIAWNGmAsjr9WrevHnyer22W7GK/XAG++EM9sMZ7Icz2tJ+aHVvQgAAdAxt6gwIANB+EEAAACsIIACAFQQQAMAKAggAYEWbCaAlS5aoR48eiouL09ChQ/Xvf//bdksRN3/+fHk8npBLv379bLfV4jZv3qxx48YpKytLHo9Ha9euDbnfGKO5c+cqMzNT8fHxys/P1969e+0024IutB+mTJly1vExduxYO822kOLiYl1//fVKSEhQWlqaxo8frz179oRsU19fr8LCQl1xxRXq0qWLJkyYoKqqKksdt4yL2Q8jR44863iYPn26pY6b1yYCaMWKFZo1a5bmzZunzz77TLm5uRozZoyOHDliu7WIu+aaa3T48OHg5eOPP7bdUourra1Vbm6ulixZ0uz9Cxcu1PPPP68XX3xRn376qS677DKNGTNG9fX1Ee60ZV1oP0jS2LFjQ46PN954I4IdtrzS0lIVFhZq69at+uCDD9TY2KjRo0ertrY2uM0jjzyid955R6tWrVJpaakOHTqkO++802LX4Xcx+0GSpk6dGnI8LFy40FLH52DagCFDhpjCwsLg9aamJpOVlWWKi4stdhV58+bNM7m5ubbbsEqSWbNmTfB6IBAwGRkZ5plnngneVl1dbbxer3njjTcsdBgZP98PxhgzefJkc/vtt1vpx5YjR44YSaa0tNQYc+Z7HxMTY1atWhXc5uuvvzaSzJYtW2y12eJ+vh+MMWbEiBHm4YcfttfURWj1Z0ANDQ3avn278vPzg7dFRUUpPz9fW7ZssdiZHXv37lVWVpZ69uype++9V/v377fdklXl5eWqrKwMOT6SkpI0dOjQDnl8bNq0SWlpaerbt68efPBBHT9+3HZLLaqmpkaSlJKSIknavn27GhsbQ46Hfv36qVu3bu36ePj5fvjB66+/rtTUVA0YMEBz5szRqVOnbLR3Tq1uGvbPHTt2TE1NTUpPTw+5PT09Xbt377bUlR1Dhw5VSUmJ+vbtq8OHD2vBggW66aabtGvXLiUkJNhuz4rKykpJavb4+OG+jmLs2LG68847lZOTo3379umPf/yjCgoKtGXLFkVHR9tuL+wCgYBmzpypYcOGacCAAZLOHA+xsbFKTk4O2bY9Hw/N7QdJuueee9S9e3dlZWVp586deuyxx7Rnzx6tXr3aYrehWn0A4UcFBQXBfw8aNEhDhw5V9+7dtXLlSt1///0WO0NrMGnSpOC/Bw4cqEGDBqlXr17atGmTRo0aZbGzllFYWKhdu3Z1iNdBz+dc+2HatGnBfw8cOFCZmZkaNWqU9u3bp169ekW6zWa1+qfgUlNTFR0dfda7WKqqqpSRkWGpq9YhOTlZffr0UVlZme1WrPnhGOD4OFvPnj2VmpraLo+PoqIivfvuu/roo49C/n5YRkaGGhoaVF1dHbJ9ez0ezrUfmjN06FBJalXHQ6sPoNjYWA0ePFgbNmwI3hYIBLRhwwbl5eVZ7My+kydPat++fcrMzLTdijU5OTnKyMgIOT58Pp8+/fTTDn98HDhwQMePH29Xx4cxRkVFRVqzZo02btyonJyckPsHDx6smJiYkONhz5492r9/f7s6Hi60H5qzY8cOSWpdx4Ptd0FcjDfffNN4vV5TUlJi/vvf/5pp06aZ5ORkU1lZabu1iPr9739vNm3aZMrLy80nn3xi8vPzTWpqqjly5Ijt1lrUiRMnzOeff24+//xzI8k8++yz5vPPPzffffedMcaYp59+2iQnJ5u3337b7Ny509x+++0mJyfH1NXVWe48vM63H06cOGFmz55ttmzZYsrLy82HH35orr32WtO7d29TX19vu/WwefDBB01SUpLZtGmTOXz4cPBy6tSp4DbTp0833bp1Mxs3bjTbtm0zeXl5Ji8vz2LX4Xeh/VBWVmb+9Kc/mW3btpny8nLz9ttvm549e5rhw4db7jxUmwggY4xZvHix6datm4mNjTVDhgwxW7dutd1SxE2cONFkZmaa2NhY84tf/MJMnDjRlJWV2W6rxX300UdG0lmXyZMnG2POvBX7qaeeMunp6cbr9ZpRo0aZPXv22G26BZxvP5w6dcqMHj3adO3a1cTExJju3bubqVOntrv/pDX3+CWZZcuWBbepq6szDz30kLn88stN586dzR133GEOHz5sr+kWcKH9sH//fjN8+HCTkpJivF6vueqqq8wf/vAHU1NTY7fxn+HvAQEArGj1rwEBANonAggAYAUBBACwggACAFhBAAEArCCAAABWEEAAACsIIACAFQQQAMAKAggAYAUBBACw4v8Bd1zFiErGC3QAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# TODO: Explore the data, display some input images\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "label_class = ['top', 'trouser', 'pullover', 'dress', 'coat', 'sandal', 'shirt', 'sneaker', 'bag', 'ankle boot']\n",
        "\n",
        "# np.random.seed(0)\n",
        "idx = np.random.randint(X_train.shape[0])\n",
        "\n",
        "plt.imshow(X_train[idx], cmap=\"gray_r\")\n",
        "plt.title(label_class[y_train[idx]])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1CN3ucsuUICK"
      },
      "source": [
        "**Before going further**: what methods could you use to perform such a classification task?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P92U8E0eUICK"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Ipym2LzUICK"
      },
      "source": [
        "The first method you will try is using neural networks. First step is the data preparation: data rescaling, label preparation.\n",
        "\n",
        "Hint: you can use the Keras function `to_categorical`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BGHom_YZUICK",
        "outputId": "e17ece6f-95e4-4398-d149-67ac80fbea50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28)\n",
            "(60000, 784)\n"
          ]
        }
      ],
      "source": [
        "# TODO: Make the data preparation\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "y_train_cat = to_categorical(y_train, num_classes=10)\n",
        "y_test_cat = to_categorical(y_test, num_classes=10)\n",
        "\n",
        "X_train_norm = X_train/255\n",
        "X_test_norm = X_test/255\n",
        "\n",
        "# TODO: reshape the image data (2D array) into input 1D array for a neural network\n",
        "print(np.shape(X_train_norm))\n",
        "X_train_norm = X_train_norm.reshape(X_train_norm.shape[0], np.prod(X_train_norm.shape[1:]))\n",
        "print(np.shape(X_train_norm))\n",
        "X_test_norm = X_test_norm.reshape(X_test_norm.shape[0], np.prod(X_test_norm.shape[1:]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tPHhs5joUICK"
      },
      "source": [
        "Next step: model building with Keras. Build your neural network architecture. At first, I would recommend a light architecture: no more than 2 hidden layers, with about 10 units per layer. Put that model into a function, so that you can reuse it later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "hzWWgQ_uUICK",
        "outputId": "a0dc2456-581b-46d3-b634-d9486531c73d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m7,850\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m110\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m110\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">7,850</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m8,070\u001b[0m (31.52 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,070</span> (31.52 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m8,070\u001b[0m (31.52 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">8,070</span> (31.52 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# TODO: Build your model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "def my_model(input_dim):\n",
        "    # Create the Sequential object\n",
        "    model = Sequential()\n",
        "\n",
        "    # Add 2 dense layers with 10 neurons each using sigmoid or relu activation\n",
        "    model.add(Dense(10, input_dim=input_dim, activation=\"sigmoid\"))\n",
        "    model.add(Dense(10, activation=\"sigmoid\"))\n",
        "\n",
        "    # Add the output layer with one unit: the predicted result\n",
        "    model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "    return model\n",
        "\n",
        "my_model(X_train_norm.shape[1]).summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g5fe9e5kUICK"
      },
      "source": [
        "Now compile and fit your model on your training data. Since this is a multiclass classification, the loss is not `binary_crossentropy` anymore, but `categorical_crossentropy`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5dgjEjyRUICL",
        "outputId": "a7591d35-5605-482d-ceed-e0f84ad9ba4a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.2627 - loss: 2.1418\n",
            "Epoch 2/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5137 - loss: 1.4771\n",
            "Epoch 3/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.6813 - loss: 1.1114\n",
            "Epoch 4/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7213 - loss: 0.9050\n",
            "Epoch 5/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7325 - loss: 0.7857\n",
            "Epoch 6/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7574 - loss: 0.7133\n",
            "Epoch 7/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7900 - loss: 0.6520\n",
            "Epoch 8/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8108 - loss: 0.5811\n",
            "Epoch 9/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8248 - loss: 0.5357\n",
            "Epoch 10/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8353 - loss: 0.5081\n",
            "Epoch 11/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8419 - loss: 0.4814\n",
            "Epoch 12/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8459 - loss: 0.4635\n",
            "Epoch 13/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8528 - loss: 0.4438\n",
            "Epoch 14/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8523 - loss: 0.4405\n",
            "Epoch 15/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8562 - loss: 0.4295\n",
            "Epoch 16/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8581 - loss: 0.4177\n",
            "Epoch 17/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8604 - loss: 0.4110\n",
            "Epoch 18/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8594 - loss: 0.4069\n",
            "Epoch 19/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8645 - loss: 0.3953\n",
            "Epoch 20/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8653 - loss: 0.3943\n",
            "Epoch 21/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8638 - loss: 0.3884\n",
            "Epoch 22/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8671 - loss: 0.3818\n",
            "Epoch 23/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8671 - loss: 0.3823\n",
            "Epoch 24/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8699 - loss: 0.3759\n",
            "Epoch 25/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8706 - loss: 0.3720\n",
            "Epoch 26/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8715 - loss: 0.3691\n",
            "Epoch 27/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8711 - loss: 0.3640\n",
            "Epoch 28/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8733 - loss: 0.3639\n",
            "Epoch 29/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8717 - loss: 0.3641\n",
            "Epoch 30/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8738 - loss: 0.3616\n",
            "Epoch 31/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8755 - loss: 0.3549\n",
            "Epoch 32/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8756 - loss: 0.3574\n",
            "Epoch 33/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8751 - loss: 0.3579\n",
            "Epoch 34/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8756 - loss: 0.3511\n",
            "Epoch 35/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8772 - loss: 0.3488\n",
            "Epoch 36/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8773 - loss: 0.3429\n",
            "Epoch 37/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8754 - loss: 0.3502\n",
            "Epoch 38/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8803 - loss: 0.3408\n",
            "Epoch 39/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8796 - loss: 0.3404\n",
            "Epoch 40/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8773 - loss: 0.3450\n",
            "Epoch 41/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8795 - loss: 0.3384\n",
            "Epoch 42/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8815 - loss: 0.3379\n",
            "Epoch 43/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8812 - loss: 0.3363\n",
            "Epoch 44/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8827 - loss: 0.3335\n",
            "Epoch 45/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8827 - loss: 0.3328\n",
            "Epoch 46/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8840 - loss: 0.3294\n",
            "Epoch 47/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8851 - loss: 0.3293\n",
            "Epoch 48/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8839 - loss: 0.3295\n",
            "Epoch 49/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8843 - loss: 0.3290\n",
            "Epoch 50/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8833 - loss: 0.3313\n",
            "Epoch 51/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8829 - loss: 0.3286\n",
            "Epoch 52/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8857 - loss: 0.3250\n",
            "Epoch 53/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8856 - loss: 0.3248\n",
            "Epoch 54/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8870 - loss: 0.3245\n",
            "Epoch 55/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8846 - loss: 0.3232\n",
            "Epoch 56/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8860 - loss: 0.3210\n",
            "Epoch 57/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8866 - loss: 0.3217\n",
            "Epoch 58/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8869 - loss: 0.3212\n",
            "Epoch 59/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8879 - loss: 0.3195\n",
            "Epoch 60/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8851 - loss: 0.3210\n",
            "Epoch 61/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8847 - loss: 0.3248\n",
            "Epoch 62/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8873 - loss: 0.3210\n",
            "Epoch 63/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8883 - loss: 0.3161\n",
            "Epoch 64/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8903 - loss: 0.3117\n",
            "Epoch 65/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8899 - loss: 0.3140\n",
            "Epoch 66/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8898 - loss: 0.3153\n",
            "Epoch 67/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8903 - loss: 0.3133\n",
            "Epoch 68/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8897 - loss: 0.3094\n",
            "Epoch 69/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8904 - loss: 0.3126\n",
            "Epoch 70/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8887 - loss: 0.3157\n",
            "Epoch 71/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8905 - loss: 0.3109\n",
            "Epoch 72/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8932 - loss: 0.3042\n",
            "Epoch 73/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8906 - loss: 0.3106\n",
            "Epoch 74/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8908 - loss: 0.3129\n",
            "Epoch 75/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8901 - loss: 0.3119\n",
            "Epoch 76/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8901 - loss: 0.3109\n",
            "Epoch 77/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8895 - loss: 0.3084\n",
            "Epoch 78/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8892 - loss: 0.3116\n",
            "Epoch 79/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8920 - loss: 0.3086\n",
            "Epoch 80/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8894 - loss: 0.3091\n",
            "Epoch 81/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.8932 - loss: 0.3080\n",
            "Epoch 82/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8930 - loss: 0.3036\n",
            "Epoch 83/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8938 - loss: 0.3044\n",
            "Epoch 84/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8950 - loss: 0.2993\n",
            "Epoch 85/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8932 - loss: 0.3044\n",
            "Epoch 86/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8934 - loss: 0.3026\n",
            "Epoch 87/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.8938 - loss: 0.3031\n",
            "Epoch 88/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8925 - loss: 0.3055\n",
            "Epoch 89/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8930 - loss: 0.2998\n",
            "Epoch 90/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8931 - loss: 0.3021\n",
            "Epoch 91/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8921 - loss: 0.3042\n",
            "Epoch 92/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8938 - loss: 0.3035\n",
            "Epoch 93/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8957 - loss: 0.2956\n",
            "Epoch 94/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8950 - loss: 0.2960\n",
            "Epoch 95/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8949 - loss: 0.2996\n",
            "Epoch 96/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8930 - loss: 0.2981\n",
            "Epoch 97/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8936 - loss: 0.3015\n",
            "Epoch 98/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8945 - loss: 0.3004\n",
            "Epoch 99/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8944 - loss: 0.3027\n",
            "Epoch 100/100\n",
            "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.8932 - loss: 0.3004\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7ff88d05e4d0>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "#https://stackoverflow.com/questions/53014306/error-15-initializing-libiomp5-dylib-but-found-libiomp5-dylib-already-initial\n",
        "# os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
        "\n",
        "# TODO: Compile and fit your model\n",
        "model = my_model(X_train_norm.shape[1])\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train_norm, y_train_cat, epochs=100, batch_size=128)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9eV23GBzUICL"
      },
      "source": [
        "Once your model has been trained, compute the accuracy (and other metrics if you want) on the train and test dataset.\n",
        "\n",
        "Be careful, Keras returns softmax output (so an array of 10 values between 0 and 1, for which the sum is equal to 1). To compute correctly the accuracy, you have to convert that array into a categorical array with zeros and a 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EknnqrFTUICL",
        "outputId": "054812a7-eefd-45ab-83f3-64321ea7949b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy on train with NN: 0.8967999815940857\n",
            "accuracy on test with NN: 0.8579000234603882\n"
          ]
        }
      ],
      "source": [
        "# TODO: Compute the accuracy of your model\n",
        "print('accuracy on train with NN:', model.evaluate(X_train_norm, y_train_cat, verbose=0)[1])\n",
        "print('accuracy on test with NN:', model.evaluate(X_test_norm, y_test_cat, verbose=0)[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jjx-h6dsUICL"
      },
      "source": [
        "What do you think of those results? Can you improve it by changing the number of layers? Of units per layer? The number of epochs? The activation functions?\n",
        "\n",
        "You should try!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wsT82Iu1UICL"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZdS-GLgVUICL"
      },
      "source": [
        "In order to compare your results with more traditional machine learning methods, you will do this work with another method: a PCA followed by a classification model (of your choice). Of course, you can perform hyperparameter optimization using a gridsearch on that model!\n",
        "\n",
        "Fit your model and display the performances."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ry1W0ZXYUICL"
      },
      "outputs": [],
      "source": [
        "# TODO: Redo the classification with PCA and classification model\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "pca = PCA(n_components=0.9)\n",
        "\n",
        "pca.fit(X_train_norm)\n",
        "X_train_pca = pca.transform(X_train_norm)\n",
        "X_test_pca = pca.transform(X_test_norm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "TlaI1jx5UICL",
        "outputId": "cca7444f-787c-4201-9d88-e1943b6cf3a6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "score with RF on train 1.0\n",
            "score with RF on train 0.861\n"
          ]
        }
      ],
      "source": [
        "# TODO: use any classifier you want\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rf = RandomForestClassifier()\n",
        "\n",
        "rf.fit(X_train_pca, y_train)\n",
        "\n",
        "print('score with RF on train', rf.score(X_train_pca, y_train))\n",
        "print('score with RF on train', rf.score(X_test_pca, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "si8kmCQUUICL"
      },
      "source": [
        "Are the performances different? Can you explain why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QF_Oju1eUICL"
      },
      "source": [
        "If you still have time, you could try to use scikit-learn's `Pipeline` to perform the hyperparameter optimization jointly on the PCA and the classification model. This might improve your performances."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}